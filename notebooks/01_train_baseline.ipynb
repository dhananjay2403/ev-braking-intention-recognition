{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daea0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc05a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from models.lstm_cnn_attention import LSTMCNNAttention\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2cdeb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check for LSTM-CNN-Attention model\n",
    "\n",
    "model = LSTMCNNAttention()\n",
    "\n",
    "x = torch.randn(8, 75, 3)  # batch of 8 samples\n",
    "y = model(x)\n",
    "\n",
    "print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98bdd7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 75, 3])\n",
      "Reconstructed shape: torch.Size([4, 75, 3])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check for Autoencoder \n",
    "\n",
    "from models.sequence_autoencoder import SequenceAutoencoder\n",
    "\n",
    "ae = SequenceAutoencoder()\n",
    "\n",
    "x = torch.randn(4, 75, 3)\n",
    "recon = ae(x)\n",
    "\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Reconstructed shape:\", recon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cbaaf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10500, 75, 3) (10500,)\n",
      "Val shape: (2250, 75, 3) (2250,)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-generated dataset\n",
    "X_train = np.load(\"../data/X_train.npy\")\n",
    "y_train = np.load(\"../data/y_train.npy\")\n",
    "\n",
    "X_val = np.load(\"../data/X_val.npy\")\n",
    "y_val = np.load(\"../data/y_val.npy\")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Val shape:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "038c9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "'''\n",
    "    Why?\n",
    "    PyTorch models only work with tensors\n",
    "    Labels must be long for classification\n",
    "'''\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype = torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype = torch.long)\n",
    "\n",
    "X_val_t = torch.tensor(X_val, dtype = torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7f7aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = LSTMCNNAttention()\n",
    "\n",
    "# Loss & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "# Training params\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249c3634",
   "metadata": {},
   "source": [
    "Simple. No tuning yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b320a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, X, y, optimizer, criterion, batch_size):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    num_batches = (len(X) + batch_size - 1) // batch_size\n",
    "\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        xb = X[i:i + batch_size]\n",
    "        yb = y[i:i + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim = 1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Batch {i//batch_size + 1}/{num_batches} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    acc = correct / len(X)\n",
    "    return total_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94fa7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Loop\n",
    "\n",
    "def evaluate(model, X, y, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        total_loss = loss.item()\n",
    "        preds = outputs.argmax(dim = 1)\n",
    "        correct = (preds == y).sum().item()\n",
    "\n",
    "    acc = correct / len(X)\n",
    "    return total_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102c97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, X_train_t, y_train_t, optimizer, criterion, BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = evaluate(\n",
    "        model, X_val_t, y_val_t, criterion\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "        f\"Train Acc: {train_acc:.3f} | \"\n",
    "        f\"Val Acc: {val_acc:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecba6c1",
   "metadata": {},
   "source": [
    "```\n",
    "Batch 1/165 - Loss: 1.0990\n",
    "Batch 2/165 - Loss: 1.0990\n",
    "Batch 3/165 - Loss: 1.0894\n",
    "Batch 4/165 - Loss: 1.0835\n",
    "Batch 5/165 - Loss: 1.0903\n",
    "...\n",
    "Batch 163/165 - Loss: 0.0109\n",
    "Batch 164/165 - Loss: 0.0107\n",
    "Batch 165/165 - Loss: 0.0208\n",
    "```\n",
    "\n",
    "Epoch 15/15 | Train Acc: 0.986 | Val Acc: 0.997"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b4d69e",
   "metadata": {},
   "source": [
    "On synthetic data, you should see:\n",
    "\n",
    "- accuracy quickly rise above 90%\n",
    "- validation track training closely\n",
    "\n",
    "That confirms:\n",
    "- dataset is usable\n",
    "- model is learning\n",
    "- pipeline is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ebe67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: torch.Size([2250, 75, 3]) torch.Size([2250])\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "X_test = np.load(\"../data/X_test.npy\")\n",
    "y_test = np.load(\"../data/y_test.npy\")\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "print(\"Test shape:\", X_test_t.shape, y_test_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cfcbb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.998\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = evaluate(\n",
    "    model, X_test_t, y_test_t, criterion\n",
    ")\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3481361e",
   "metadata": {},
   "source": [
    "You should expect:\n",
    "- Test accuracy ‚âà validation accuracy\n",
    "- Slight drop is okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8e2b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[775   4   0]\n",
      " [  0 711   0]\n",
      " [  0   0 760]]\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Light Braking       1.00      0.99      1.00       779\n",
      "   Normal Braking       0.99      1.00      1.00       711\n",
      "Emergency Braking       1.00      1.00      1.00       760\n",
      "\n",
      "         accuracy                           1.00      2250\n",
      "        macro avg       1.00      1.00      1.00      2250\n",
      "     weighted avg       1.00      1.00      1.00      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_t)\n",
    "    preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, preds, target_names=[\n",
    "    \"Light Braking\", \"Normal Braking\", \"Emergency Braking\"\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f55c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save trained model\n",
    "torch.save(model.state_dict(), \"../models/lstm_cnn_attention_baseline.pth\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45609656",
   "metadata": {},
   "source": [
    "Files after saving this model \n",
    "\n",
    "models/\n",
    "- lstm_cnn_attention.py\n",
    "- lstm_cnn_attention_baseline.pth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833a03a",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa5deabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = SequenceAutoencoder()\n",
    "\n",
    "ae_criterion = nn.MSELoss()\n",
    "ae_optimizer = optim.Adam(ae.parameters(), lr=1e-3)\n",
    "\n",
    "AE_EPOCHS = 20\n",
    "AE_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da91921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Autoencoder \n",
    "def train_autoencoder(model, X, optimizer, criterion, batch_size):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        xb = X[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon = model(xb)\n",
    "        loss = criterion(recon, xb)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3557f0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE Epoch 1/20 | Reconstruction Loss: 1.573429\n",
      "AE Epoch 2/20 | Reconstruction Loss: 0.075039\n",
      "AE Epoch 3/20 | Reconstruction Loss: 0.025374\n",
      "AE Epoch 4/20 | Reconstruction Loss: 0.017062\n",
      "AE Epoch 5/20 | Reconstruction Loss: 0.004242\n",
      "AE Epoch 6/20 | Reconstruction Loss: 0.000468\n",
      "AE Epoch 7/20 | Reconstruction Loss: 0.000388\n",
      "AE Epoch 8/20 | Reconstruction Loss: 0.000373\n",
      "AE Epoch 9/20 | Reconstruction Loss: 0.000358\n",
      "AE Epoch 10/20 | Reconstruction Loss: 0.000344\n",
      "AE Epoch 11/20 | Reconstruction Loss: 0.000329\n",
      "AE Epoch 12/20 | Reconstruction Loss: 0.000314\n",
      "AE Epoch 13/20 | Reconstruction Loss: 0.000300\n",
      "AE Epoch 14/20 | Reconstruction Loss: 0.000285\n",
      "AE Epoch 15/20 | Reconstruction Loss: 0.000271\n",
      "AE Epoch 16/20 | Reconstruction Loss: 0.000258\n",
      "AE Epoch 17/20 | Reconstruction Loss: 0.000245\n",
      "AE Epoch 18/20 | Reconstruction Loss: 0.000233\n",
      "AE Epoch 19/20 | Reconstruction Loss: 0.000221\n",
      "AE Epoch 20/20 | Reconstruction Loss: 0.000210\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(AE_EPOCHS):\n",
    "    loss = train_autoencoder(\n",
    "        ae, X_train_t, ae_optimizer, ae_criterion, AE_BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    print(f\"AE Epoch {epoch+1}/{AE_EPOCHS} | Reconstruction Loss: {loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5aa3c47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder saved.\n"
     ]
    }
   ],
   "source": [
    "# Save trained Autoencoder \n",
    "torch.save(ae.state_dict(), \"../models/sequence_autoencoder.pth\")\n",
    "\n",
    "print(\"Autoencoder saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8fe8949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# AE + Classifier Sanity check\n",
    "from models.lstm_cnn_attention import AE_LSTMCNNAttention\n",
    "\n",
    "ae_model = AE_LSTMCNNAttention()\n",
    "\n",
    "x = torch.randn(4, 75, 3)\n",
    "y = ae_model(x)\n",
    "\n",
    "print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76b589f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the integrated model\n",
    "ae_classifier = AE_LSTMCNNAttention()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, ae_classifier.parameters()),\n",
    "    lr = 1e-3\n",
    ")\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb9f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        ae_classifier, X_train_t, y_train_t,\n",
    "        optimizer, criterion, BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = evaluate(\n",
    "        ae_classifier, X_val_t, y_val_t, criterion\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[AE+CLS] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "        f\"Train Acc: {train_acc:.3f} | \"\n",
    "        f\"Val Acc: {val_acc:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78398d47",
   "metadata": {},
   "source": [
    "```\n",
    "Batch 1/165 - Loss: 1.0949\n",
    "Batch 2/165 - Loss: 1.0915\n",
    "Batch 3/165 - Loss: 1.0816\n",
    "Batch 4/165 - Loss: 1.0733\n",
    "Batch 5/165 - Loss: 1.0732\n",
    "...\n",
    "Batch 163/165 - Loss: 0.0027\n",
    "Batch 164/165 - Loss: 0.0032\n",
    "Batch 165/165 - Loss: 0.0004\n",
    "```\n",
    "\n",
    "[AE+CLS] Epoch 15/15 | Train Acc: 0.996 | Val Acc: 0.994"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94bf66",
   "metadata": {},
   "source": [
    "## Test-set evaluation for AE + Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set shape: torch.Size([2250, 75, 3]) torch.Size([2250])\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "X_test = np.load(\"../data/X_test.npy\")\n",
    "y_test = np.load(\"../data/y_test.npy\")\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype = torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype = torch.long)\n",
    "\n",
    "print(\"Test set shape:\", X_test_t.shape, y_test_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dbf02a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AE+CLS] Test Accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(\n",
    "    ae_classifier, X_test_t, y_test_t, criterion\n",
    ")\n",
    "\n",
    "print(f\"[AE+CLS] Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f0109c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (AE+CLS):\n",
      " [[779   0   0]\n",
      " [ 16 695   0]\n",
      " [  0   0 760]]\n",
      "\n",
      "Classification Report (AE+CLS):\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Light Braking       0.98      1.00      0.99       779\n",
      "   Normal Braking       1.00      0.98      0.99       711\n",
      "Emergency Braking       1.00      1.00      1.00       760\n",
      "\n",
      "         accuracy                           0.99      2250\n",
      "        macro avg       0.99      0.99      0.99      2250\n",
      "     weighted avg       0.99      0.99      0.99      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "ae_classifier.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = ae_classifier(X_test_t)\n",
    "    preds = outputs.argmax(dim = 1).cpu().numpy()\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(\"Confusion Matrix (AE+CLS):\\n\", cm)\n",
    "\n",
    "print(\"\\nClassification Report (AE+CLS):\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    preds,\n",
    "    target_names = [\"Light Braking\", \"Normal Braking\", \"Emergency Braking\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fdd4e1",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "Test results:\n",
    "\n",
    "Test Accuracy: 99.29%\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "    Light     ‚Üí almost perfect\n",
    "    Normal    ‚Üí small confusion with Light (16 samples)\n",
    "    Emergency ‚Üí perfect\n",
    "\n",
    "This tells us three important things:\n",
    "\n",
    "‚úÖ (1) No train‚Äìtest leakage\n",
    "\n",
    "If there was leakage:\n",
    "- test accuracy would be ~100%\n",
    "- confusion matrix would be perfectly diagonal\n",
    "\n",
    "But we do have:\n",
    "- small, realistic confusion (Normal ‚Üî Light)\n",
    "- slightly lower test accuracy than val\n",
    "\n",
    "This is healthy.\n",
    "\n",
    "‚úÖ (2) Emergency braking is learned robustly\n",
    "\n",
    "This is critical for both real-world relevance & research credibility\n",
    "\n",
    "Emergency braking:\n",
    "- Precision = 1.00\n",
    "- Recall = 1.00\n",
    "\n",
    "This means the model has learned clear temporal patterns for emergency braking, not just thresholds.\n",
    "\n",
    "‚ö†Ô∏è (3) The data distribution is still ‚Äúeasy‚Äù\n",
    "\n",
    "Your concern was:\n",
    "\n",
    "‚ÄúThe model has learned the data instead of understanding patterns.‚Äù\n",
    "\n",
    "The correct refined statement is:\n",
    "\n",
    "‚ÄúThe model understands patterns very well ‚Äî but the patterns themselves are still too clean and consistent.‚Äù\n",
    "\n",
    "This is a data realism issue, not a model issue. That‚Äôs an important distinction.\n",
    "\n",
    "2Ô∏è‚É£ So‚Ä¶ is this a problem?\n",
    "‚ùå No, this is NOT a problem at this stage\n",
    "‚úÖ This is actually the expected outcome\n",
    "\n",
    "Why?\n",
    "- You deliberately started with clean synthetic data & controlled distributions\n",
    "- This is baseline + first innovation validation\n",
    "\n",
    "In real ML workflows:\n",
    "- Validate architecture correctness ‚úÖ (done)\n",
    "- Validate training pipeline correctness ‚úÖ (done)\n",
    "- Validate controlled generalization ‚úÖ (done)\n",
    "- Then stress-test realism ‚ùó (next step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb873027",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Adding noise and domain shift to test data\n",
    "\n",
    "1. Sensor noise (Gaussian noise)\n",
    "\n",
    "    Simulates:\n",
    "    - speed sensor jitter\n",
    "    - acceleration noise\n",
    "    - pedal sensor imperfections\n",
    "\n",
    "2. Brake pedal delay\n",
    "\n",
    "    Simulates:\n",
    "    - human reaction delay\n",
    "    - actuator lag\n",
    "\n",
    "3. Feature scaling drift\n",
    "\n",
    "    Simulates:\n",
    "    - calibration differences\n",
    "    - different vehicles / drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create noisy / shifted test data\n",
    "def add_sensor_noise(X, noise_std = 0.05):\n",
    "\n",
    "    noise = np.random.normal(0, noise_std, X.shape)\n",
    "    return X + noise\n",
    "\n",
    "\n",
    "def add_brake_delay(X, delay_steps = 3):\n",
    "\n",
    "    X_delayed = X.copy()\n",
    "    X_delayed[:, delay_steps:, 2] = X[:, :-delay_steps, 2]\n",
    "    X_delayed[:, :delay_steps, 2] = 0.0\n",
    "    return X_delayed\n",
    "\n",
    "\n",
    "def apply_feature_drift(X, scale_range = (0.9, 1.1)):\n",
    "\n",
    "    scales = np.random.uniform(\n",
    "        scale_range[0],\n",
    "        scale_range[1],\n",
    "        size = (1, 1, X.shape[2])\n",
    "    )\n",
    "    return X * scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stressed test set created.\n"
     ]
    }
   ],
   "source": [
    "# Copy original test data\n",
    "X_test_stress = X_test.copy()\n",
    "\n",
    "# Apply noise & domain shift\n",
    "X_test_stress = add_sensor_noise(X_test_stress, noise_std=0.08)\n",
    "X_test_stress = add_brake_delay(X_test_stress, delay_steps=4)\n",
    "X_test_stress = apply_feature_drift(X_test_stress)\n",
    "\n",
    "# Convert to tensor\n",
    "X_test_stress_t = torch.tensor(\n",
    "    X_test_stress,\n",
    "    dtype = torch.float32\n",
    ")\n",
    "\n",
    "print(\"Stressed test set created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f748d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AE+CLS] Stress Test Accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "# Evaluate AE + CLS on stressed test set\n",
    "stress_loss, stress_acc = evaluate(\n",
    "    ae_classifier,\n",
    "    X_test_stress_t,\n",
    "    y_test_t,\n",
    "    criterion\n",
    ")\n",
    "\n",
    "print(f\"[AE+CLS] Stress Test Accuracy: {stress_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c64a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (AE+CLS ‚Äì Stressed):\n",
      " [[779   0   0]\n",
      " [  5 696  10]\n",
      " [  0   0 760]]\n",
      "\n",
      "Classification Report (AE+CLS ‚Äì Stressed):\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Light Braking       0.99      1.00      1.00       779\n",
      "   Normal Braking       1.00      0.98      0.99       711\n",
      "Emergency Braking       0.99      1.00      0.99       760\n",
      "\n",
      "         accuracy                           0.99      2250\n",
      "        macro avg       0.99      0.99      0.99      2250\n",
      "     weighted avg       0.99      0.99      0.99      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "ae_classifier.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = ae_classifier(X_test_stress_t)\n",
    "    preds = outputs.argmax(dim = 1).cpu().numpy()\n",
    "\n",
    "cm_stress = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Confusion Matrix (AE+CLS ‚Äì Stressed):\\n\", cm_stress)\n",
    "\n",
    "print(\"\\nClassification Report (AE+CLS ‚Äì Stressed):\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    preds,\n",
    "    target_names = [\"Light Braking\", \"Normal Braking\", \"Emergency Braking\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d629c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Stress Test Accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "# Compare with baseline\n",
    "baseline_loss, baseline_stress_acc = evaluate(\n",
    "    model,  # baseline LSTM-CNN-Attention\n",
    "    X_test_stress_t,\n",
    "    y_test_t,\n",
    "    criterion\n",
    ")\n",
    "\n",
    "print(f\"[Baseline] Stress Test Accuracy: {baseline_stress_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e08849d",
   "metadata": {},
   "source": [
    "#### Why didn‚Äôt accuracy drop meaningfully?\n",
    "\n",
    "The labels are still trivially recoverable even after noise & shift.\n",
    "\n",
    "The synthetic data has very strong label‚Äìfeature coupling, likely something like:\n",
    "- Light braking ‚Üí low brake pedal, mild decel\n",
    "- Normal braking ‚Üí moderate, smooth patterns\n",
    "- Emergency braking ‚Üí very strong, sustained signals\n",
    "\n",
    "Even after:\n",
    "- Gaussian noise\n",
    "- Small delays\n",
    "- Feature scaling\n",
    "\n",
    "#### Why the stress test didn‚Äôt truly stress the model\n",
    "\n",
    "‚ùå What we changed\n",
    "- Added noise\n",
    "- Shifted brake pedal\n",
    "- Scaled features\n",
    "\n",
    "‚ùå What we did NOT change (this is the problem)\n",
    "- Class overlap\n",
    "- Ambiguous braking events\n",
    "- Mixed braking styles\n",
    "- Temporal inconsistency\n",
    "- Label uncertainty\n",
    "\n",
    "In real driving:\n",
    "- Light vs Normal braking often overlap\n",
    "- Emergency braking is not always ‚Äúmax pedal‚Äù\n",
    "- Drivers brake inconsistently\n",
    "- Signals contradict each other\n",
    "\n",
    "The synthetic generator currently never produces ambiguity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8aa452",
   "metadata": {},
   "source": [
    "---\n",
    "How real research papers avoid this trap\n",
    "\n",
    "Good ML-for-control papers do one (or more) of the following:\n",
    "1. Predict future intention (harder)\n",
    "2. Introduce class overlap\n",
    "3. Use soft / probabilistic labels\n",
    "4. Mix braking modes in one window\n",
    "5. Train on one distribution, test on another\n",
    "\n",
    "We currently have:\n",
    "- Same generator\n",
    "- Same logic\n",
    "- Same label rules\n",
    "\n",
    "    ‚Üí even noisy data still follows the same rules\n",
    "\n",
    "---\n",
    "\n",
    "Now we'll make the task genuinely harder\n",
    "\n",
    "‚Üí Ambiguous + overlapping braking data\n",
    "\n",
    "This means:\n",
    "- Light & Normal braking overlap intentionally\n",
    "- Emergency braking sometimes looks ‚Äúnormal‚Äù at first\n",
    "- Label is based on future behavior, not current\n",
    "\n",
    "This is the right scientific fix.\n",
    "\n",
    "- Makes accuracy drop meaningfully\n",
    "- Tests temporal understanding\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185eedc5",
   "metadata": {},
   "source": [
    "## Loading hard dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ad48a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard train: (10500, 75, 3) (10500,)\n",
      "Hard val: (2250, 75, 3) (2250,)\n",
      "Hard test: (2250, 75, 3) (2250,)\n"
     ]
    }
   ],
   "source": [
    "# Load HARD dataset\n",
    "X_train_h = np.load(\"../data/X_train_hard.npy\")\n",
    "y_train_h = np.load(\"../data/y_train_hard.npy\")\n",
    "\n",
    "X_val_h = np.load(\"../data/X_val_hard.npy\")\n",
    "y_val_h = np.load(\"../data/y_val_hard.npy\")\n",
    "\n",
    "X_test_h = np.load(\"../data/X_test_hard.npy\")\n",
    "y_test_h = np.load(\"../data/y_test_hard.npy\")\n",
    "\n",
    "print(\"Hard train:\", X_train_h.shape, y_train_h.shape)\n",
    "print(\"Hard val:\", X_val_h.shape, y_val_h.shape)\n",
    "print(\"Hard test:\", X_test_h.shape, y_test_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "29572508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_h_t = torch.tensor(X_train_h, dtype = torch.float32)\n",
    "y_train_h_t = torch.tensor(y_train_h, dtype = torch.long)\n",
    "\n",
    "X_val_h_t = torch.tensor(X_val_h, dtype = torch.float32)\n",
    "y_val_h_t = torch.tensor(y_val_h, dtype = torch.long)\n",
    "\n",
    "X_test_h_t = torch.tensor(X_test_h, dtype = torch.float32)\n",
    "y_test_h_t = torch.tensor(y_test_h, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a FRESH baseline model\n",
    "baseline_hard = LSTMCNNAttention()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(baseline_hard.parameters(), lr = 1e-3)\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline on HARD data\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        baseline_hard,\n",
    "        X_train_h_t,\n",
    "        y_train_h_t,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = evaluate(\n",
    "        baseline_hard,\n",
    "        X_val_h_t,\n",
    "        y_val_h_t,\n",
    "        criterion\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[Baseline-HARD] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "        f\"Train Acc: {train_acc:.3f} | \"\n",
    "        f\"Val Acc: {val_acc:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a12d41",
   "metadata": {},
   "source": [
    "```\n",
    "Batch 1/165 - Loss: 1.1109\n",
    "Batch 2/165 - Loss: 1.0942\n",
    "Batch 3/165 - Loss: 1.0847\n",
    "Batch 4/165 - Loss: 1.1155\n",
    "Batch 5/165 - Loss: 1.1121\n",
    "...\n",
    "Batch 163/165 - Loss: 0.5760\n",
    "Batch 164/165 - Loss: 0.5711\n",
    "Batch 165/165 - Loss: 0.1820\n",
    "```\n",
    "\n",
    "[Baseline-HARD] Epoch 20/20 | Train Acc: 0.712 | Val Acc: 0.719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e589681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline-HARD] Test Accuracy: 0.6956\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline on HARD test set\n",
    "test_loss_h, test_acc_h = evaluate(\n",
    "    baseline_hard,\n",
    "    X_test_h_t,\n",
    "    y_test_h_t,\n",
    "    criterion\n",
    ")\n",
    "\n",
    "print(f\"[Baseline-HARD] Test Accuracy: {test_acc_h:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43ac9dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Baseline-HARD):\n",
      " [[598 193   3]\n",
      " [217 487 102]\n",
      " [ 12 158 480]]\n",
      "\n",
      "Classification Report (Baseline-HARD):\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Light Braking       0.72      0.75      0.74       794\n",
      "   Normal Braking       0.58      0.60      0.59       806\n",
      "Emergency Braking       0.82      0.74      0.78       650\n",
      "\n",
      "         accuracy                           0.70      2250\n",
      "        macro avg       0.71      0.70      0.70      2250\n",
      "     weighted avg       0.70      0.70      0.70      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "baseline_hard.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = baseline_hard(X_test_h_t)\n",
    "    preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "cm_hard = confusion_matrix(y_test_h, preds)\n",
    "\n",
    "print(\"Confusion Matrix (Baseline-HARD):\\n\", cm_hard)\n",
    "\n",
    "print(\"\\nClassification Report (Baseline-HARD):\")\n",
    "print(classification_report(\n",
    "    y_test_h,\n",
    "    preds,\n",
    "    target_names = [\"Light Braking\", \"Normal Braking\", \"Emergency Braking\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e1f19",
   "metadata": {},
   "source": [
    "Confusion matrix interpretation:\n",
    "\n",
    "- Light ‚Üî Normal: heavy confusion ‚úÖ\n",
    "- Emergency: still relatively strong ‚úÖ\n",
    "- No class collapse ‚úÖ\n",
    "\n",
    "\n",
    "Analyzing class-wise behavior:\n",
    "\n",
    "1. Light Braking\n",
    "- Precision: 0.72\n",
    "- Recall: 0.75\n",
    "\n",
    "    ‚Üí Reasonable, but confused with Normal (expected)\n",
    "\n",
    "2. Normal Braking (hardest class)\n",
    "- Precision: 0.58\n",
    "- Recall: 0.60\n",
    "\n",
    "    ‚Üí This is exactly what real data looks like\n",
    "    ‚Üí Normal braking sits between light and emergency\n",
    "\n",
    "3. Emergency Braking\n",
    "- Precision: 0.82\n",
    "- Recall: 0.74\n",
    "\n",
    "    ‚Üí Still learned reasonably well\n",
    "    ‚Üí Good sign for safety-critical behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5267e4",
   "metadata": {},
   "source": [
    "Baseline-HARD results (~69.6%)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30e33ab",
   "metadata": {},
   "source": [
    "## Training AE+CLS on HARD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_cnn_attention import AE_LSTMCNNAttention\n",
    "\n",
    "ae_cls_hard = AE_LSTMCNNAttention(latent_dim = 4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "    Encoder is frozen\n",
    "    Only CNN, LSTM, Attention, FC train\n",
    "'''\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, ae_cls_hard.parameters()),\n",
    "    lr = 1e-3\n",
    ")\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AE+CLS on HARD data\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        ae_cls_hard,\n",
    "        X_train_h_t,\n",
    "        y_train_h_t,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = evaluate(\n",
    "        ae_cls_hard,\n",
    "        X_val_h_t,\n",
    "        y_val_h_t,\n",
    "        criterion\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"[AE+CLS-HARD] Epoch {epoch+1}/{EPOCHS} | \"\n",
    "        f\"Train Acc: {train_acc:.3f} | \"\n",
    "        f\"Val Acc: {val_acc:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19145e",
   "metadata": {},
   "source": [
    "```\n",
    "Batch 1/165 - Loss: 1.1026\n",
    "Batch 2/165 - Loss: 1.1007\n",
    "Batch 3/165 - Loss: 1.1172\n",
    "Batch 4/165 - Loss: 1.0882\n",
    "Batch 5/165 - Loss: 1.0946\n",
    "...\n",
    "Batch 163/165 - Loss: 0.5834\n",
    "Batch 164/165 - Loss: 0.5618\n",
    "Batch 165/165 - Loss: 0.1900\n",
    "```\n",
    "\n",
    "[AE+CLS-HARD] Epoch 20/20 | Train Acc: 0.709 | Val Acc: 0.646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6294013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AE+CLS-HARD] Test Accuracy: 0.6409\n"
     ]
    }
   ],
   "source": [
    "# Evaluate AE+CLS on HARD test set\n",
    "test_loss_h_ae, test_acc_h_ae = evaluate(\n",
    "    ae_cls_hard,\n",
    "    X_test_h_t,\n",
    "    y_test_h_t,\n",
    "    criterion\n",
    ")\n",
    "\n",
    "print(f\"[AE+CLS-HARD] Test Accuracy: {test_acc_h_ae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a7126b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (AE+CLS-HARD):\n",
      " [[376 393  25]\n",
      " [ 77 502 227]\n",
      " [  2  84 564]]\n",
      "\n",
      "Classification Report (AE+CLS-HARD):\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "    Light Braking       0.83      0.47      0.60       794\n",
      "   Normal Braking       0.51      0.62      0.56       806\n",
      "Emergency Braking       0.69      0.87      0.77       650\n",
      "\n",
      "         accuracy                           0.64      2250\n",
      "        macro avg       0.68      0.65      0.64      2250\n",
      "     weighted avg       0.67      0.64      0.64      2250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "ae_cls_hard.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = ae_cls_hard(X_test_h_t)\n",
    "    preds = outputs.argmax(dim = 1).cpu().numpy()\n",
    "\n",
    "cm_hard_ae = confusion_matrix(y_test_h, preds)\n",
    "\n",
    "print(\"Confusion Matrix (AE+CLS-HARD):\\n\", cm_hard_ae)\n",
    "\n",
    "print(\"\\nClassification Report (AE+CLS-HARD):\")\n",
    "print(classification_report(\n",
    "    y_test_h,\n",
    "    preds,\n",
    "    target_names = [\"Light Braking\", \"Normal Braking\", \"Emergency Braking\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d8d03",
   "metadata": {},
   "source": [
    "#### HARD dataset results\n",
    "\n",
    "Model\t            Test Accuracy\n",
    "Baseline (HARD)\t    0.6956\n",
    "AE + CLS (HARD)\t    0.6409\n",
    "\n",
    "So yes ‚Äî AE+CLS performs worse than baseline on HARD data.\n",
    "\n",
    "This is not a failure. It's a meaningful scientific outcome.\n",
    "\n",
    "Key observation\n",
    "- The autoencoder helped on easy data\n",
    "- The autoencoder hurt on ambiguous HARD data\n",
    "\n",
    "Why? Because of one design choice we made on purpose:\n",
    "\n",
    "üîí We froze the encoder\n",
    "\n",
    "That means:\n",
    "- The encoder learned representations optimized for reconstruction\n",
    "- Not optimized for discriminating subtle class boundaries\n",
    "- On HARD data, discrimination matters more than denoising\n",
    "\n",
    "So the AE is currently acting like a constraint, not a helper.\n",
    "\n",
    "\n",
    "Confusion matrix tells the full story\n",
    "\n",
    "AE+CLS-HARD confusion highlights\n",
    "\n",
    "üî¥ Light Braking\n",
    "- Recall dropped to 0.47\n",
    "- Many light samples pushed into Normal\n",
    "- Means: encoder compressed away subtle differences\n",
    "\n",
    "üü° Normal Braking\n",
    "- Recall 0.62 (slightly better than Light)\n",
    "- Still very ambiguous (expected)\n",
    "\n",
    "üü¢ Emergency Braking\n",
    "- Recall 0.87 ‚Üí best-performing class\n",
    "- This is actually very good\n",
    "- AE preserved strong, salient signals\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "The autoencoder preserves high-energy / dominant patterns well (emergency braking), but suppresses fine-grained distinctions (light vs normal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123da4b0",
   "metadata": {},
   "source": [
    "---\n",
    "We've now demonstrated three important things:\n",
    "\n",
    "1. Data difficulty matters more than model complexity\n",
    "2. Representation learning is not universally beneficial\n",
    "3. Frozen encoders can harm discriminative tasks under ambiguity\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbd8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d6974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8d77e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3207bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6dd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638abc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358cc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42874b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801eaea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea0e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
